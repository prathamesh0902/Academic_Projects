{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleanning on anime & anime_with_synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "Load"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from surprise import dump\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "from proj_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH = './Data'\n",
    "\n",
    "anime = pd.read_csv(f'{PATH}/anime.csv')\n",
    "anime_with_synopsis = pd.read_csv(f'{PATH}/anime_with_synopsis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {'Unknown': np.nan}\n",
    "anime_with_synopsis = anime_with_synopsis.replace(replace_dict)\n",
    "anime = anime.replace(replace_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change genre into itemset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_with_synopsis['Genres'] = anime_with_synopsis['Genres'].apply(lambda x: set((str(x)).strip().split(', ')))\n",
    "anime['Genres'] = anime['Genres'].apply(lambda x: set((str(x)).strip().split(', ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set()\n",
    "for i in anime_with_synopsis['Genres'].to_numpy():\n",
    "    genres = genres.union(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Action',\n",
       " 'Adventure',\n",
       " 'Cars',\n",
       " 'Comedy',\n",
       " 'Dementia',\n",
       " 'Demons',\n",
       " 'Drama',\n",
       " 'Ecchi',\n",
       " 'Fantasy',\n",
       " 'Game',\n",
       " 'Harem',\n",
       " 'Historical',\n",
       " 'Horror',\n",
       " 'Josei',\n",
       " 'Kids',\n",
       " 'Magic',\n",
       " 'Martial Arts',\n",
       " 'Mecha',\n",
       " 'Military',\n",
       " 'Music',\n",
       " 'Mystery',\n",
       " 'Parody',\n",
       " 'Police',\n",
       " 'Psychological',\n",
       " 'Romance',\n",
       " 'Samurai',\n",
       " 'School',\n",
       " 'Sci-Fi',\n",
       " 'Seinen',\n",
       " 'Shoujo',\n",
       " 'Shoujo Ai',\n",
       " 'Shounen',\n",
       " 'Shounen Ai',\n",
       " 'Slice of Life',\n",
       " 'Space',\n",
       " 'Sports',\n",
       " 'Super Power',\n",
       " 'Supernatural',\n",
       " 'Thriller',\n",
       " 'Vampire',\n",
       " 'Yaoi',\n",
       " 'nan'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_with_synopsis = anime_with_synopsis.replace({'sypnopsis': '^No synopsis information.*$'}, {'sypnopsis': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(anime_with_synopsis[anime_with_synopsis['Genres'] == {'nan'}])\n",
    "display(anime[anime['Genres'] == {'nan'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_with_synopsis['Genres'] = anime_with_synopsis['Genres'].apply(lambda x: x - {'nan'})\n",
    "anime['Genres'] = anime['Genres'].apply(lambda x: x - {'nan'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = anime.astype({k: 'float' for k in ['Score-10', 'Score-9', 'Score-8', 'Score-7', 'Score-6',\n",
    "       'Score-5', 'Score-4', 'Score-3', 'Score-2', 'Score-1']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['English name'] = anime['English name'].apply(clean_string)\n",
    "anime_with_synopsis['Name'] = anime_with_synopsis['Name'].apply(clean_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "factor premired date into the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_from_string(season_str: str):\n",
    "    '''Convert string of premired year into year'''\n",
    "    r = re.compile('(\\w+)\\W*(\\d+)')\n",
    "    if type(season_str) != str:\n",
    "        return np.nan \n",
    "    splitted = r.findall(season_str)\n",
    "    if len(splitted) != 1:\n",
    "        return np.nan\n",
    "\n",
    "    return int(splitted[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['Premiered Year'] = anime['Premiered'].apply(get_year_from_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime['Premiered Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for seachable title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_for_search = pd.DataFrame({\n",
    "    'MAL_ID': anime['MAL_ID'],\n",
    "    'Name': anime['Name'], \n",
    "    'English name': anime['English name'],\n",
    "    'Japanese name': anime['Japanese name'],\n",
    "    'Genres': anime['Genres'],\n",
    "    'Avg. Score': anime['Score']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "vectorizer_en = TfidfVectorizer(ngram_range=(1, 2))\n",
    "tfidf = vectorizer.fit_transform(anime_for_search['Name'])\n",
    "tfidf_en = vectorizer_en.fit_transform(anime_for_search['English name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('./Model/search_TfidfVectorizer.pkl', '+wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "with open('./Model/search_TfidfVectorizer_en.pkl', '+wb') as f:\n",
    "    pickle.dump(vectorizer_en, f)\n",
    "\n",
    "with open('./Data/search_tfidf.pkl', '+wb') as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "with open('./Data/search_tfidf_en.pkl', '+wb') as f:\n",
    "    pickle.dump(tfidf_en, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "anime_with_synopsis.to_feather('./Data/anime_with_synopsis.feather')\n",
    "anime.to_feather('./Data/anime.feather')\n",
    "anime_for_search.to_feather('./Data/anime_for_search.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "Load"
    ]
   },
   "outputs": [],
   "source": [
    "with open('./Model/search_TfidfVectorizer.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "    assert(isinstance(vectorizer, TfidfVectorizer))\n",
    "with open('./Model/search_TfidfVectorizer_en.pkl', 'rb') as f:\n",
    "    vectorizer_en = pickle.load(f)\n",
    "    assert(isinstance(vectorizer_en, TfidfVectorizer))\n",
    "\n",
    "with open('./Data/search_tfidf.pkl', 'rb') as f:\n",
    "    tfidf = pickle.load(f)\n",
    "with open('./Data/search_tfidf_en.pkl', 'rb') as f:\n",
    "    tfidf_en = pickle.load(f)\n",
    "\n",
    "anime_with_synopsis = pd.read_feather('./Data/anime_with_synopsis.feather')\n",
    "anime = pd.read_feather('./Data/anime.feather')\n",
    "anime_for_search = pd.read_feather('./Data/anime_for_search.feather')\n",
    "\n",
    "def search(keyword: str):\n",
    "    return search_util(keyword, vectorizer, vectorizer_en, tfidf, tfidf_en, anime_for_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAL_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>English name</th>\n",
       "      <th>Japanese name</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Avg. Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>One Piece</td>\n",
       "      <td>One Piece</td>\n",
       "      <td>ONE PIECE</td>\n",
       "      <td>[Adventure, Action, Shounen, Comedy, Fantasy, ...</td>\n",
       "      <td>8.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6842</th>\n",
       "      <td>12859</td>\n",
       "      <td>One Piece Film: Z</td>\n",
       "      <td>One Piece Film Z</td>\n",
       "      <td>ワンピース　フィルム　﻿Ｚ</td>\n",
       "      <td>[Adventure, Action, Shounen, Comedy, Fantasy, ...</td>\n",
       "      <td>8.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5260</th>\n",
       "      <td>8171</td>\n",
       "      <td>One Piece Recap</td>\n",
       "      <td>One Piece Recap</td>\n",
       "      <td>ワンピース</td>\n",
       "      <td>[Adventure, Action, Shounen, Comedy, Fantasy, ...</td>\n",
       "      <td>7.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7385</th>\n",
       "      <td>16143</td>\n",
       "      <td>One Piece: Kinkyuu Kikaku One Piece Kanzen Kou...</td>\n",
       "      <td>One Piece:Emergency Planning, A Perfect Strate...</td>\n",
       "      <td>緊急企画ワンピース完全攻略法</td>\n",
       "      <td>[Comedy, Adventure, Shounen, Fantasy]</td>\n",
       "      <td>7.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14553</th>\n",
       "      <td>37902</td>\n",
       "      <td>One Piece: Episode of Sorajima</td>\n",
       "      <td>One Piece:Episode of Skypiea</td>\n",
       "      <td>ONE PIECE エピソードオブ空島</td>\n",
       "      <td>[Adventure, Action, Shounen, Comedy, Fantasy, ...</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>462</td>\n",
       "      <td>One Piece Movie 4: Dead End no Bouken</td>\n",
       "      <td>One Piece:Dead End</td>\n",
       "      <td>ワンピース デッドエンドの冒険</td>\n",
       "      <td>[Adventure, Action, Shounen, Comedy, Fantasy, ...</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>4155</td>\n",
       "      <td>One Piece Film: Strong World</td>\n",
       "      <td>One Piece Film Strong World</td>\n",
       "      <td>ワンピース　フィルム　ストロングワールド</td>\n",
       "      <td>[Adventure, Action, Shounen, Comedy, Fantasy, ...</td>\n",
       "      <td>8.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13502</th>\n",
       "      <td>36240</td>\n",
       "      <td>Scratch x One Piece Film: Gold</td>\n",
       "      <td>Scratch x One Piece Film:Gold</td>\n",
       "      <td>SCRATCH × ONE PIECE FILM GOLD</td>\n",
       "      <td>[Fantasy, Shounen]</td>\n",
       "      <td>6.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>5252</td>\n",
       "      <td>One Piece: Romance Dawn Story</td>\n",
       "      <td>One Piece:Romance Dawn Story</td>\n",
       "      <td>ワンピース ロマンスドーンストーリー</td>\n",
       "      <td>[Action, Shounen, Comedy, Fantasy, Super Power]</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>460</td>\n",
       "      <td>One Piece Movie 2: Nejimaki-jima no Daibouken</td>\n",
       "      <td>One Piece:Clockwork Island Adventure</td>\n",
       "      <td>ワンピース ねじまき島の冒険</td>\n",
       "      <td>[Adventure, Action, Shounen, Comedy, Fantasy, ...</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MAL_ID                                               Name  \\\n",
       "11         21                                          One Piece   \n",
       "6842    12859                                  One Piece Film: Z   \n",
       "5260     8171                                    One Piece Recap   \n",
       "7385    16143  One Piece: Kinkyuu Kikaku One Piece Kanzen Kou...   \n",
       "14553   37902                     One Piece: Episode of Sorajima   \n",
       "433       462              One Piece Movie 4: Dead End no Bouken   \n",
       "3524     4155                       One Piece Film: Strong World   \n",
       "13502   36240                     Scratch x One Piece Film: Gold   \n",
       "4048     5252                      One Piece: Romance Dawn Story   \n",
       "431       460      One Piece Movie 2: Nejimaki-jima no Daibouken   \n",
       "\n",
       "                                            English name  \\\n",
       "11                                             One Piece   \n",
       "6842                                    One Piece Film Z   \n",
       "5260                                     One Piece Recap   \n",
       "7385   One Piece:Emergency Planning, A Perfect Strate...   \n",
       "14553                       One Piece:Episode of Skypiea   \n",
       "433                                   One Piece:Dead End   \n",
       "3524                         One Piece Film Strong World   \n",
       "13502                      Scratch x One Piece Film:Gold   \n",
       "4048                        One Piece:Romance Dawn Story   \n",
       "431                 One Piece:Clockwork Island Adventure   \n",
       "\n",
       "                       Japanese name  \\\n",
       "11                         ONE PIECE   \n",
       "6842                   ワンピース　フィルム　﻿Ｚ   \n",
       "5260                           ワンピース   \n",
       "7385                  緊急企画ワンピース完全攻略法   \n",
       "14553            ONE PIECE エピソードオブ空島   \n",
       "433                  ワンピース デッドエンドの冒険   \n",
       "3524            ワンピース　フィルム　ストロングワールド   \n",
       "13502  SCRATCH × ONE PIECE FILM GOLD   \n",
       "4048              ワンピース ロマンスドーンストーリー   \n",
       "431                   ワンピース ねじまき島の冒険   \n",
       "\n",
       "                                                  Genres Avg. Score  \n",
       "11     [Adventure, Action, Shounen, Comedy, Fantasy, ...       8.52  \n",
       "6842   [Adventure, Action, Shounen, Comedy, Fantasy, ...       8.18  \n",
       "5260   [Adventure, Action, Shounen, Comedy, Fantasy, ...       7.16  \n",
       "7385               [Comedy, Adventure, Shounen, Fantasy]       7.15  \n",
       "14553  [Adventure, Action, Shounen, Comedy, Fantasy, ...       7.11  \n",
       "433    [Adventure, Action, Shounen, Comedy, Fantasy, ...       7.59  \n",
       "3524   [Adventure, Action, Shounen, Comedy, Fantasy, ...       8.17  \n",
       "13502                                 [Fantasy, Shounen]       6.14  \n",
       "4048     [Action, Shounen, Comedy, Fantasy, Super Power]       7.39  \n",
       "431    [Adventure, Action, Shounen, Comedy, Fantasy, ...       7.17  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('One piece')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime[anime['Genres'].apply(lambda x: 'Hentai' in x) | anime['Score'].isna()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleanning on Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating = pd.read_csv('./Data/animelist.csv')\n",
    "# rating_complete = pd.read_csv('./Data/rating_complete.csv')\n",
    "# rating.to_feather('./Data/animelist.feather')\n",
    "# rating_complete.to_feather('./Data/rating_complete.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After save as feather binary file, load this instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "Load"
    ]
   },
   "outputs": [],
   "source": [
    "rating = pd.read_feather('./Data/animelist.feather')\n",
    "rating_complete = pd.read_feather('./Data/rating_complete.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating['rating'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the rating on `anime_id` is refer to `MAL_ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_ids = rating_complete['anime_id'].unique()\n",
    "np.setdiff1d(anime_ids, anime['MAL_ID'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just try to add count into the anime file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA (Ratings)\n",
    "Checking how many reviews for each anime, it appears that there are some anime which is so popular that there are more than 100,000 reviews on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_hist = rating_complete.loc[:, ['anime_id', 'rating']].groupby(by='anime_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_hist[rating_hist['rating'] < 2e4].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_hist[rating_hist['rating'] > 1e5].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the with rating with synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_with_synopsis_with_count = rating_hist.join(anime_with_synopsis.set_index('MAL_ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_with_synopsis_with_count.columns = ['rating_completed_count', 'Name', 'Score', 'Genres', 'sypnopsis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_with_synopsis_with_count.sort_values(by='rating_completed_count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation System (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the dataset for performance reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = rating_complete['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310059,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 0.05\n",
    "focus_user_id, _ = train_test_split(user_ids, train_size=0.05, random_state=42)\n",
    "focus_rating = rating_complete[rating_complete['user_id'].isin(focus_user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(focus_user_id.shape)\n",
    "print(focus_rating.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_rating.shape[0] / focus_user_id.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 10))\n",
    "dataset = Dataset.load_from_df(focus_rating[['user_id', 'anime_id', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd = SVD()\n",
    "# cross_validate(svd, dataset, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
    "\n",
    "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
    "RMSE (testset)    1.1765  1.1749  1.1763  1.1759  0.0007  \n",
    "MAE (testset)     0.8790  0.8777  0.8789  0.8785  0.0006  \n",
    "Fit time          12.93   12.49   12.95   12.79   0.21    \n",
    "Test time         6.14    6.15    6.26    6.18    0.05    \n",
    "{'test_rmse': array([1.1765492 , 1.17493892, 1.17632392]),\n",
    " 'test_mae': array([0.87901695, 0.87771758, 0.87887208]),\n",
    " 'fit_time': (12.930427074432373, 12.493419647216797, 12.945121049880981),\n",
    " 'test_time': (6.144198894500732, 6.145112037658691, 6.2577879428863525)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn = KNNBasic()\n",
    "# cross_validate(knn, dataset, cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Computing the msd similarity matrix...\n",
    "Done computing similarity matrix.\n",
    "Computing the msd similarity matrix...\n",
    "Done computing similarity matrix.\n",
    "Computing the msd similarity matrix...\n",
    "Done computing similarity matrix.\n",
    "Evaluating RMSE, MAE of algorithm KNNBasic on 3 split(s).\n",
    "\n",
    "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
    "RMSE (testset)    1.2941  1.2918  1.2924  1.2928  0.0010  \n",
    "MAE (testset)     0.9587  0.9581  0.9584  0.9584  0.0002  \n",
    "Fit time          190.73  171.00  173.67  178.47  8.74    \n",
    "Test time         598.17  549.93  575.58  574.56  19.71   \n",
    "{'test_rmse': array([1.29408973, 1.29182792, 1.29243483]),\n",
    " 'test_mae': array([0.95870405, 0.95810879, 0.9584189 ]),\n",
    " 'fit_time': (190.73062705993652, 170.99515986442566, 173.67348313331604),\n",
    " 'test_time': (598.1731100082397, 549.9259850978851, 575.5787467956543)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_options = sim_options = {\n",
    "#     \"name\": \"cosine\",\n",
    "#     \"user_based\": False,  # compute  similarities between items\n",
    "# }\n",
    "# knn = KNNBasic(sim_options=sim_options)\n",
    "# cross_validate(knn, dataset, cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Computing the cosine similarity matrix...\n",
    "Done computing similarity matrix.\n",
    "Computing the cosine similarity matrix...\n",
    "Done computing similarity matrix.\n",
    "Computing the cosine similarity matrix...\n",
    "Done computing similarity matrix.\n",
    "Evaluating RMSE, MAE of algorithm KNNBasic on 3 split(s).\n",
    "\n",
    "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
    "RMSE (testset)    1.3754  1.3752  1.3734  1.3747  0.0009  \n",
    "MAE (testset)     1.0304  1.0302  1.0292  1.0299  0.0005  \n",
    "Fit time          88.27   103.83  104.06  98.72   7.39    \n",
    "Test time         159.00  161.31  167.64  162.65  3.65    \n",
    "{'test_rmse': array([1.37540845, 1.37515701, 1.37341346]),\n",
    " 'test_mae': array([1.03036109, 1.0302266 , 1.02920084]),\n",
    " 'fit_time': (88.27486371994019, 103.82556104660034, 104.05858612060547),\n",
    " 'test_time': (159.00390911102295, 161.3134388923645, 167.64093279838562)}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = dataset.build_full_trainset()\n",
    "# svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump.dump('./Model/svd.pkl', svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#   'n_factors': [20, 50, 100],\n",
    "#   'n_epochs': [5, 10, 20]\n",
    "# }\n",
    " \n",
    "# gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "# gs.fit(dataset)\n",
    " \n",
    "# print(gs.best_score['rmse'])\n",
    "# print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1.1458925132330084\n",
    "{'n_factors': 20, 'n_epochs': 20}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(n_factors=20, n_epochs=20)\n",
    "svd.fit(dataset.build_full_trainset())\n",
    "dump.dump('./Model/svd.pkl', svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_rating[focus_rating['user_id'] == focus_user_id[100]].set_index('anime_id').join(anime_for_search.set_index('MAL_ID'))\n",
    "x = search('Kara no Kyoukai 4')\n",
    "x['Predict Score'] = x['MAL_ID'].apply(lambda id: svd.predict(uid=focus_user_id[0], iid=id).est)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_rating.reset_index().to_feather('./Data/For_SVD/focus_rating.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Model for recommender system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 0.2\n",
    "focus_user_id_2, _ = train_test_split(user_ids, train_size=size, random_state=42)\n",
    "focus_rating_2 = rating_complete[rating_complete['user_id'].isin(focus_user_id_2)]\n",
    "focus_rating_2 = focus_rating_2.reset_index()\n",
    "focus_rating_2.reset_index().to_feather('./Data/For_SVD/focus_rating_2.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of users: 62011\n",
      "# of ratings: 11474169\n",
      "# anime titles: 17562\n",
      "sparce ratio: 1.6126171163180727e-05\n"
     ]
    }
   ],
   "source": [
    "print(f'# of users: {len(focus_user_id_2)}')\n",
    "print(f'# of ratings: {len(focus_rating_2)}')\n",
    "print(f'# anime titles: {len(anime_for_search)}')\n",
    "print(f'sparce ratio: {len(focus_rating_2) / (len(focus_user_id_2) * len(focus_rating_2))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fb0ca1cb6d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_big = SVD(n_factors=20, n_epochs=20)\n",
    "reader_big = Reader(rating_scale=(0, 10))\n",
    "dataset_big = Dataset.load_from_df(focus_rating_2[['user_id', 'anime_id', 'rating']], reader_big)\n",
    "svd_big.fit(dataset_big.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump.dump('./Model/svd_big.pkl', svd_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_widget = widgets.Text(\n",
    "    value = '', description = 'Title'\n",
    ")\n",
    "\n",
    "search_btn = widgets.Button(\n",
    "    description='Search',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Search',\n",
    "    icon='search' \n",
    ")\n",
    "\n",
    "search_output = widgets.Output()\n",
    "\n",
    "def search_event(sender):\n",
    "    search_output.clear_output()\n",
    "    x = search_widget.value\n",
    "    if len(x) < 3:\n",
    "            return\n",
    "    with search_output:\n",
    "        display(search(x))\n",
    "\n",
    "search_btn.on_click(search_event)\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([search_widget, search_btn]), search_output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "def search_similar_users(given_review: dict, top_k = 1):\n",
    "    rank = pd.Series()\n",
    "    v = pd.DataFrame({'anime_id': given_review.keys(), 'rating': given_review.values()})\\\n",
    "        .pivot(columns='anime_id', values='rating')\n",
    "    for i in user_ids[:2000]:\n",
    "        u = focus_rating_2[focus_rating_2['user_id'] == i].pivot(index='user_id', columns='anime_id', values='rating')\n",
    "        cos_sim = cosine_similarity(pd.concat([u, v]).fillna(0))[0][1]\n",
    "\n",
    "        rank[i] = cos_sim\n",
    "        if len(rank) > top_k:\n",
    "            rank.sort_values(inplace=True, ascending=False)\n",
    "            rank = rank[:top_k]\n",
    "\n",
    "    return rank\n",
    "\n",
    "a = {235: 8, 21:10}\n",
    "x = pd.DataFrame({'anime_id': a.keys(), 'rating':a.values()})\n",
    "search_similar_users(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si671",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
